{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a297ee49-414e-4721-ad0a-14f18d965b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U transformers \n",
    "%pip install -U datasets \n",
    "%pip install -U accelerate \n",
    "%pip install -U peft \n",
    "%pip install -U trl \n",
    "%pip install -U bitsandbytes \n",
    "%pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65212f59-8233-4693-99c5-b1f4ffb5f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e75b8cc-540b-4e35-98d5-f4a2fab47807",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "dataset_name = \"ruslanmv/ai-medical-chatbot\"\n",
    "new_model = \"llama-3.2-3b-chat-doctor\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151cd79-3f22-4516-add3-6171b9624f13",
   "metadata": {},
   "source": [
    "# Loading the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70daa421-b899-4729-8963-bceb82c83b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6386a905-08b5-424b-87ac-32e05ffc15be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9daf46b553c744428c74dbbdcdfb5f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c254dbcc210b439785e0cf9b6515ae3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d734952931e64992a9d6c4cbded8a477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c48fa91fdb4a249de9a91ddd932b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546c9d7aad6b4839916c95d81c0feed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c9326496364b4cb155da0596ef86d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b536f6465cd44d33a4ee6082337ea1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73cadc27-e219-40b8-bec8-b833c2f776bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "# model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b351fc6-0028-4a9f-9db7-e4b5ef9fefd0",
   "metadata": {},
   "source": [
    "# Adding the adapter to the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c61b4b2-dd51-4ce5-b1d1-1750ff7a1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84116905-939b-4b06-bd43-34f20d74fe2c",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0abb4ad8-f99f-435e-9929-6b2b5e654da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a232a946fae74faaaccdd07e22f89247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/863 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d8f302edfd4351acc9f3b6211ee9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dialogues.parquet:   0%|          | 0.00/142M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30aef459ef704d50bdff785609897e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3515bd30b98143c58a1c08b975e9f0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Feb 2025\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nFell on sidewalk face first about 8 hrs ago. Swollen, cut lip bruised and cut knee, and hurt pride initially. Now have muscle and shoulder pain, stiff jaw(think this is from the really swollen lip),pain in wrist, and headache. I assume this is all normal but are there specific things I should look for or will I just be in pain for a while given the hard fall?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nHello and welcome to HCM,The injuries caused on various body parts have to be managed.The cut and swollen lip has to be managed by sterile dressing.The body pains, pain on injured site and jaw pain should be managed by pain killer and muscle relaxant.I suggest you to consult your primary healthcare provider for clinical assessment.In case there is evidence of infection in any of the injured sites, a course of antibiotics may have to be started to control the infection.Thanks and take careDr Shailja P Wahal<|eot_id|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "dataset = load_dataset(dataset_name, split=\"all\")\n",
    "dataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\n",
    "\n",
    "def format_chat_template(row):\n",
    "    row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},\n",
    "               {\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]\n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(\n",
    "    format_chat_template,\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "dataset['text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fed05895-7581-4dbc-a72d-4185d5b9773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce8f4339-fe36-4b72-ad5c-2ecb22efeb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    # report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abf3757c-5b44-4627-b2fb-bdb67cf1e10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_681/1448105485.py:1: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b66cdf4b67f4bcbbca8fc1d9bbc4486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2cac9c6e944b2f9d75399a4280216b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82d5e7bdfa84ef28727745afe0575e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7fce64970e487b826abdd7dbb40f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47005111de84430999a4c25443201b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1981ecca8c476eac746ef2b6b4c88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02dcced0b2d4e338f25d3a53154cf5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83f30152288459d8a52e88763eb66d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    # max_seq_length=512,\n",
    "    # dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    # packing= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9d1d65f-cb19-430b-8408-7c4810f2729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set pad_token to eos_token: <|eot_id|>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 04:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.018900</td>\n",
       "      <td>2.501708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.341600</td>\n",
       "      <td>2.466892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.343700</td>\n",
       "      <td>2.444494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.524200</td>\n",
       "      <td>2.429086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.611900</td>\n",
       "      <td>2.412898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 04:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.024400</td>\n",
       "      <td>2.443914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.502200</td>\n",
       "      <td>2.442322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.152500</td>\n",
       "      <td>2.413587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.737900</td>\n",
       "      <td>2.389509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.675400</td>\n",
       "      <td>2.384856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=2.173314309649997, metrics={'train_runtime': 245.5509, 'train_samples_per_second': 3.665, 'train_steps_per_second': 1.833, 'total_flos': 3944559839557632.0, 'train_loss': 2.173314309649997})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'tokenizer' is your tokenizer object\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding token\n",
    "    print(f\"Set pad_token to eos_token: {tokenizer.pad_token}\")\n",
    "\n",
    "# Now run training\n",
    "trainer.train()\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb0e5d-772b-4826-b088-a959620bd782",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fe1f23e-9da4-4a5b-8451-bb31e3bb75a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–ˆâ–†â–…â–„â–ƒâ–…â–„â–ƒâ–â–</td></tr><tr><td>eval/mean_token_accuracy</td><td>â–â–‚â–ƒâ–ƒâ–„â–„â–„â–‡â–‡â–ˆ</td></tr><tr><td>eval/runtime</td><td>â–ˆâ–â–…â–„â–†â–„â–„â–‚â–‚â–…</td></tr><tr><td>eval/samples_per_second</td><td>â–â–ˆâ–„â–…â–ƒâ–…â–…â–‡â–‡â–„</td></tr><tr><td>eval/steps_per_second</td><td>â–â–ˆâ–„â–…â–ƒâ–…â–…â–‡â–‡â–„</td></tr><tr><td>train/epoch</td><td>â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–†â–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–‚â–‚â–ƒâ–„â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ƒâ–…â–„â–‚â–†â–ƒâ–…â–‚â–â–…â–‚â–ƒâ–†â–„â–…â–…â–†â–ƒâ–ƒâ–ƒâ–…â–â–„â–…â–†â–†â–‡â–„â–†â–…â–‡â–ˆâ–†â–‡â–‡â–…â–†â–‡â–†â–‡</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–„â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–†â–…â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–</td></tr><tr><td>train/loss</td><td>â–†â–‡â–…â–†â–‡â–„â–‡â–…â–‡â–ˆâ–‡â–†â–„â–†â–†â–…â–‡â–…â–…â–…â–‡â–†â–‡â–†â–„â–…â–†â–â–†â–†â–…â–…â–„â–ƒâ–†â–†â–†â–‡â–„â–†</td></tr><tr><td>train/mean_token_accuracy</td><td>â–‚â–ƒâ–„â–‚â–‚â–â–ƒâ–†â–„â–ƒâ–…â–‚â–…â–†â–†â–ƒâ–ƒâ–ƒâ–„â–…â–„â–†â–‡â–ƒâ–…â–ˆâ–ƒâ–„â–†â–‚â–‡â–„â–„â–ƒâ–…â–†â–…â–†â–â–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.38486</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.50805</td></tr><tr><td>eval/runtime</td><td>8.3115</td></tr><tr><td>eval/samples_per_second</td><td>12.032</td></tr><tr><td>eval/steps_per_second</td><td>12.032</td></tr><tr><td>total_flos</td><td>3944559839557632.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>450</td></tr><tr><td>train/grad_norm</td><td>1.87341</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.6754</td></tr><tr><td>train/mean_token_accuracy</td><td>0.59878</td></tr><tr><td>train_loss</td><td>2.17331</td></tr><tr><td>train_runtime</td><td>245.5509</td></tr><tr><td>train_samples_per_second</td><td>3.665</td></tr><tr><td>train_steps_per_second</td><td>1.833</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">llama-3.2-3b-chat-doctor</strong> at: <a href='https://wandb.ai/rohitmishra/huggingface/runs/somtp641' target=\"_blank\">https://wandb.ai/rohitmishra/huggingface/runs/somtp641</a><br> View project at: <a href='https://wandb.ai/rohitmishra/huggingface' target=\"_blank\">https://wandb.ai/rohitmishra/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250227_000611-somtp641/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be9b9f5f-a1f4-4c7a-99df-31492009f655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hello. I have gone through your query and understand your concerns. Acne can be due to over production of oil by the sebaceous glands, blockage of the pores, or combination of both. It can also be due to hormonal imbalance, stress, poor hygiene, and other factors. I would recommend you to use a non-comedogenic moisturizer, a spot treatment containing salicylic acid, and a mild oral antibiotic. For further information consult a dermatologist online -->  -->\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, \n",
    "                                       add_generation_prompt=True)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, \n",
    "                   truncation=True).to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=150, \n",
    "                         num_return_sequences=1)\n",
    "\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(text.split(\"assistant\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be50c9c-2ff7-4649-bdb5-102f7383be2d",
   "metadata": {},
   "source": [
    "# Saving the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca64510d-3abb-4e9b-bd00-66cb0062e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(new_model)\n",
    "# trainer.model.push_to_hub(new_model, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae2d5b-9960-4390-9acc-5d6720eff321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
